{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prediction Ready Comp551_kaggle.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1fhI84C_HtECxoeBA0isUApIBWD2TgTzs",
          "timestamp": 1521427318011
        },
        {
          "file_id": "1S9IBEQyEU0jXHN98MsMQnErvs0u3qna6",
          "timestamp": 1521302673218
        },
        {
          "file_id": "15kgGTyI8fywA0iDADlMuM6wCWMphb38C",
          "timestamp": 1521067308100
        }
      ],
      "collapsed_sections": [
        "junj_3naCSB3"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Q7QG3A9lz7_I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports and load data"
      ]
    },
    {
      "metadata": {
        "id": "763WEq9018Ya",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb8c2b60-a21c-4f8e-fd36-f25308e64ff4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521687120660,
          "user_tz": 240,
          "elapsed": 2716,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import scipy.misc\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from __future__ import print_function\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.optimizers import Adadelta, Adam"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "qiQA3bIFG6OC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Kaggle API"
      ]
    },
    {
      "metadata": {
        "id": "m4lilvZRHAHJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8a2d5a08-8073-4124-82df-715f7f475642",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521687125957,
          "user_tz": 240,
          "elapsed": 2344,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages\r\n",
            "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle)\r\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle)\r\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle)\r\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BL3HWpLCLtMF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "448b02cf-4eb7-4e24-e068-82f6ef452752",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521687131245,
          "user_tz": 240,
          "elapsed": 4218,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vFUGcPFVbPvE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **load data**"
      ]
    },
    {
      "metadata": {
        "id": "JCY1gZVtTqOi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 4
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "65578dd3-1302-4e7c-83f4-7aeeb05fcbc6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521687289265,
          "user_tz": 240,
          "elapsed": 157683,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c comp551w18-modified-mnist -p \"./\"\n",
        "!ls\n",
        "train_x = np.loadtxt(\"./train_x.csv\", delimiter=\",\")\n",
        "train_y = np.loadtxt(\"./train_y.csv\", delimiter=\",\")\n",
        "test_x = np.loadtxt(\"./test_x.csv\", delimiter=\",\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_y.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_x.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_x.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "datalab  test_x.csv  train_x.csv  train_y.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5QhNwELoSwTJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#storing a backup copy if we accidentally overwrite data, saves from reloading\n",
        "backup_train_x = np.copy(train_x)\n",
        "backup_train_y = np.copy(train_y)\n",
        "backup_test_x = np.copy(test_x)\n",
        " \n",
        "#restore backup\n",
        "def restore():\n",
        "  train_x = np.copy(backup_train_x)\n",
        "  train_y = np.copy(backup_train_y)\n",
        "  test_x = np.copy(backup_test_x)\n",
        "  return train_x, train_y, test_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w7qvfOkkRdbB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_x = train_x.reshape(-1, 64, 64) # reshape\n",
        "train_y = train_y.reshape(-1, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "upkF3k0W4iiU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sample printed images"
      ]
    },
    {
      "metadata": {
        "id": "HQVtHu-fuhja",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "744cf075-4207-4108-93f2-6b766dd4fbff",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521687340765,
          "user_tz": 240,
          "elapsed": 2619,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_y[0],train_y[1],train_y[2],train_y[3],train_y[4])\n",
        "\n",
        "plt.subplot(221)\n",
        "plt.imshow(train_x[0],cmap='gray_r')\n",
        "plt.subplot(222)\n",
        "plt.imshow(train_x[1],cmap='gray_r')\n",
        "plt.subplot(223)\n",
        "plt.imshow(train_x[2],cmap='gray_r')\n",
        "plt.subplot(224)\n",
        "plt.imshow(train_x[3],cmap='gray_r')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.] [7.] [1.] [0.] [8.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAFNCAYAAAA0I9mzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f309c0bb588>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TeV8409-SR0x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "metadata": {
        "id": "FTlSzhqMcEzv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Black N White function"
      ]
    },
    {
      "metadata": {
        "id": "h2nvWyZtWZF7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def img_blackNwhite(img,thresh=254,maxValue=255):\n",
        "  ''' function for turning original image into black and white image\n",
        "      using threshold\n",
        "  '''\n",
        "  # turn image to binary black and white\n",
        "  th, dst = cv2.threshold(img, thresh, maxValue, cv2.THRESH_BINARY);\n",
        "  \n",
        "  # convert numpy array to unsigned 8 bit to work with FindCountours()\n",
        "  dst = dst.astype(np.uint8)\n",
        "  \n",
        "  return dst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G2pfoOpvcJhe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Remove images with touching digits"
      ]
    },
    {
      "metadata": {
        "id": "EVNxQ-MpGrjP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def remove_touching_images(X,y_label,thresh=254,maxValue=255):\n",
        "  \n",
        "  images = []\n",
        "  labels = []\n",
        "  \n",
        "  counter = -1\n",
        "  for img in X:\n",
        "    counter+=1\n",
        "    # turn image black and white\n",
        "    dst = img_blackNwhite(img,thresh,maxValue)\n",
        "  \n",
        "    # Find Contours\n",
        "    image, contours, hier = cv2.findContours(dst, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    \n",
        "    # within each image look at the bounding boxes\n",
        "    count = 0 # count is used to just append the image once \n",
        "    for cnt in contours:\n",
        "      count+=1\n",
        "      x,y,w,h = cv2.boundingRect(cnt)\n",
        "      \n",
        "      # if the dimensions are good append\n",
        "      if((w <= 36 and w > 0) and (h > 0 and h <= 36)):\n",
        "        if(count==1):\n",
        "          images.append(img)\n",
        "          labels.append(y_label[counter])\n",
        "      \n",
        "      # if the dim are not good\n",
        "      else:\n",
        "        break\n",
        "  # turn them into numpy arrays\n",
        "  images = np.asarray(images)\n",
        "  labels = np.asarray(labels)\n",
        "  \n",
        "  return images,labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_2bggFEUW9xf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "21c9b362-d78f-4954-841d-111c5b20d39c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521687352808,
          "user_tz": 240,
          "elapsed": 2876,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"before removal {0}, {1}\".format(train_x.shape,train_y.shape))\n",
        "\n",
        "train_x_wo_touching,train_y_wo_touching = remove_touching_images(train_x,train_y)\n",
        "\n",
        "print(\"after removal\")\n",
        "print(train_x_wo_touching.shape)\n",
        "print(train_y_wo_touching.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before removal (50000, 64, 64), (50000, 1)\n",
            "after removal\n",
            "(49828, 64, 64)\n",
            "(49828, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BelR0fsqfgSE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bounding images"
      ]
    },
    {
      "metadata": {
        "id": "9-nm0_NNL4G0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_bounding_image(img,thresh=254,maxValue=255):\n",
        "  \n",
        "  ''' \n",
        "      function that returns the subimages from img using bounding box approach\n",
        "      with a threshold\n",
        "      \n",
        "      - input: is a 64 x 64 image, the treshold and maxValue for seperating background\n",
        "      - return: list of subimages (as numpy matricies) from img \n",
        "  '''\n",
        "  \n",
        "  # turn image to binary black and white\n",
        "  dst = img_blackNwhite(img)\n",
        "  \n",
        "  # Find Contours\n",
        "  image, contours, hier = cv2.findContours(dst, cv2.RETR_EXTERNAL,\n",
        "                cv2.CHAIN_APPROX_SIMPLE)\n",
        "  \n",
        "  # Get images in the countours\n",
        "  images = []\n",
        "  for cnt in contours:\n",
        "    \n",
        "    x,y,w,h = cv2.boundingRect(cnt)\n",
        "    images.append(image[y:y+h,x:x+w])  \n",
        "    \n",
        "  return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1WXhvwylfj1J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Resize\n"
      ]
    },
    {
      "metadata": {
        "id": "bEyXOUDwL9fh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def resizeAndPad(img, size, padColor=0):\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "    sh, sw = size\n",
        "\n",
        "    # interpolation method\n",
        "    if h > sh or w > sw: # shrinking image\n",
        "        interp = cv2.INTER_AREA\n",
        "    else: # stretching image\n",
        "        interp = cv2.INTER_CUBIC\n",
        "\n",
        "    # aspect ratio of image\n",
        "    aspect = w/h  # if on Python 2, you might need to cast as a float: float(w)/h\n",
        "\n",
        "    # compute scaling and pad sizing\n",
        "    if aspect > 1: # horizontal image\n",
        "        new_w = sw\n",
        "        new_h = np.round(new_w/aspect).astype(int)\n",
        "        pad_vert = (sh-new_h)/2\n",
        "        pad_top, pad_bot = np.floor(pad_vert).astype(int), np.ceil(pad_vert).astype(int)\n",
        "        pad_left, pad_right = 0, 0\n",
        "    elif aspect < 1: # vertical image\n",
        "        new_h = sh\n",
        "        new_w = np.round(new_h*aspect).astype(int)\n",
        "        pad_horz = (sw-new_w)/2\n",
        "        pad_left, pad_right = np.floor(pad_horz).astype(int), np.ceil(pad_horz).astype(int)\n",
        "        pad_top, pad_bot = 0, 0\n",
        "    else: # square image\n",
        "        new_h, new_w = sh, sw\n",
        "        pad_left, pad_right, pad_top, pad_bot = 0, 0, 0, 0\n",
        "\n",
        "    # set pad color\n",
        "    if len(img.shape) is 3 and not isinstance(padColor, (list, tuple, np.ndarray)): # color image but only one color provided\n",
        "        padColor = [padColor]*3\n",
        "\n",
        "    # scale and pad\n",
        "    scaled_img = cv2.resize(img, (new_w, new_h), interpolation=interp)\n",
        "    scaled_img = cv2.copyMakeBorder(scaled_img, pad_top, pad_bot, pad_left, pad_right, borderType=cv2.BORDER_CONSTANT, value=padColor)\n",
        "\n",
        "    return scaled_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7VwYulQiByHx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def rescale_images(images,rescale_size=(20,20), pad = 4):\n",
        " \n",
        "  ''' given a set of raw images (or preprocessed images)\n",
        "     returns another set of rescaled images based on rescale_size\n",
        "     \n",
        "     images: list of images\n",
        "     rescale_size: the size we wish to resize the images to, default is 28x28\n",
        "                   the size of MNIST\n",
        "     return: list of resized images\n",
        " '''\n",
        "  scaled_images=[]\n",
        " \n",
        "  for image in images:\n",
        "    # get subimages\n",
        "    sub_images =  get_bounding_image(image)\n",
        "    for sub_img in sub_images:\n",
        "      # resize\n",
        "      dst = resizeAndPad(sub_img, rescale_size, padColor= 0)\n",
        "      #padding\n",
        "      dst = cv2.copyMakeBorder(dst, pad, pad, pad, pad, borderType=0)\n",
        "      #save\n",
        "      scaled_images.append(dst)\n",
        " \n",
        "  return np.asarray(scaled_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UJPr0HN7DY6q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def rescale(image,rescale_size=(20,20), pad = 4):\n",
        "  \n",
        "  ''' function for rescaling just one image\n",
        "  \n",
        "      input: a bounding box type image\n",
        "      return: rescaled image close to MNIST\n",
        "  '''\n",
        "  dst = resizeAndPad(image, rescale_size, padColor= 0)\n",
        "  #padding\n",
        "  dst = cv2.copyMakeBorder(dst, pad, pad, pad, pad, borderType=0)\n",
        "  return dst \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LmLXTYhHdvms",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Methods for picking the largest subimage"
      ]
    },
    {
      "metadata": {
        "id": "qPBaFRsKflq5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Count pixels"
      ]
    },
    {
      "metadata": {
        "id": "LP9wzLd4EqLP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def count_pixels(image):\n",
        "  ''' returns the count of all the non zero pixel in an image\n",
        "  '''\n",
        "  counter = 0\n",
        "  for row in image:\n",
        "    for element in row:\n",
        "      if (element != 0): counter +=1\n",
        "  return counter\n",
        "\n",
        "def count_pixels_gray(image):\n",
        "  ''' returns the sum of all the non zero pixel in an image\n",
        "  '''\n",
        "  norm = image/255\n",
        "  counter = 0\n",
        "  for row in norm:\n",
        "    for element in row:\n",
        "      if (element != 0): counter += element\n",
        "  return counter\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tqZN1WKSFLVU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## find largest based on area"
      ]
    },
    {
      "metadata": {
        "id": "bIe-Fx8WErnc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# a way of choosing between the subimages for a given image\n",
        "def find_largest_count(images):\n",
        "  \n",
        "  '''\n",
        "     given a set of subimages, returns the subimage that was the largest in area\n",
        "     \n",
        "     images: set of subimages, like the ones return by get_bounding_image\n",
        "     return: numpy array of largest integer \n",
        "  '''\n",
        "  \n",
        "  counts=[]\n",
        "  for img in images:\n",
        "    counts.append(count_pixels_gray(img))\n",
        "\n",
        "  index = counts.index(max(counts))  \n",
        "  \n",
        "  return images[index]\n",
        "\n",
        "# a way of choosing between the subimages for a given image\n",
        "def find_largest_axes(images):\n",
        "  \n",
        "  '''\n",
        "     given a set of subimages, returns the subimage that was the largest in area\n",
        "     \n",
        "     images: set of subimages, like the ones return by get_bounding_image\n",
        "     return: numpy array of largest integer \n",
        "  '''\n",
        "  \n",
        "  counts=[]\n",
        "  for img in images:\n",
        "\n",
        "    counts.append(max(img.shape))\n",
        "\n",
        "  index = counts.index(max(counts))  \n",
        "  \n",
        "  return images[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uH_jzGEjFTaf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## find largest based on ratio"
      ]
    },
    {
      "metadata": {
        "id": "S79U59oGLduX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# another way of choosing between the subimages for a given image\n",
        "\n",
        "def find_largest_count_ratio(images):\n",
        "  '''\n",
        "      returns largest subimage based on the ratio of pixel counts between the actual subimage and the MNIST scaled version\n",
        "  '''\n",
        "  \n",
        "  count_ratios=[]\n",
        "  for img in images:\n",
        "\n",
        "    pre_scaled_count = count_pixels_gray(img)\n",
        "    \n",
        "    post_scaled = rescale(img)\n",
        "    post_scaled_count = count_pixels_gray(post_scaled)\n",
        "    \n",
        "    ratio = pre_scaled_count/post_scaled_count\n",
        "  \n",
        "    count_ratios.append( ratio )\n",
        "  \n",
        "  # find the max image based on ratio\n",
        "  max_val = max(count_ratios)\n",
        "  index = count_ratios.index(max_val) \n",
        "  \n",
        "  return images[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t0oVCrPveCYA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Changing the dataset to just contain one subimage"
      ]
    },
    {
      "metadata": {
        "id": "eXCT9P89MTmO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Replacing dataset with chosen images"
      ]
    },
    {
      "metadata": {
        "id": "T-418HvzMQAg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def new_data(data,method):\n",
        "  \n",
        "  ''' \n",
        "    function to go from dataset --> upto 3 preprocessed subimages \n",
        "    return the X given a method of choosing between the subimages\n",
        "    (for example using find_largest_count or looking at ratios)\n",
        "    \n",
        "    we go from raw data to data that just has one subimage included\n",
        "    \n",
        "    input: raw image data\n",
        "    return: chosen subimages data\n",
        "  '''\n",
        "  \n",
        "  new_data = []\n",
        "  \n",
        "  for image in data:\n",
        "   # get subimgs\n",
        "    sub_images =  get_bounding_image(image.reshape(64,64))\n",
        "    #find the largest one\n",
        "    largest = method(sub_images)    \n",
        "    #resize it\n",
        "    dst = rescale(largest)\n",
        "    #dst = resizeAndPad(largest, (28,28), padColor= 0) # previous way of rescaling img\n",
        "    #save it\n",
        "    new_data.append(dst)\n",
        "\n",
        "  return np.asarray(new_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gwZkZRR4MzI_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3d87139f-7ff5-4ac5-a0d2-051fdee5371f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521688465862,
          "user_tz": 240,
          "elapsed": 57283,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#runing code to get modified dataset \n",
        "\n",
        "print(train_x_wo_touching.shape)\n",
        "new_x_train_data = new_data(train_x_wo_touching,find_largest_count_ratio)\n",
        "\n",
        "# Uncomment code below to get a dataset using find_largest_axes instead:\n",
        "#new_x_train_data = new_data(train_x_wo_touching,find_largest_axes) \n",
        "\n",
        "print(new_x_train_data.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49828, 64, 64)\n",
            "(49828, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FQ0jpiADKTab",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "def transform_image(img,ang_range, shear_range):\n",
        "    '''\n",
        "    This function transforms images to generate new images.\n",
        "    The function takes in following arguments,\n",
        "    1- Image\n",
        "    2- ang_range: Range of angles for rotation\n",
        "    3- shear_range: Range of values to apply affine transform to\n",
        "    4- trans_range: Range of values to apply translations over.\n",
        "\n",
        "    A Random uniform distribution is used to generate different parameters for transformation\n",
        "\n",
        "    '''\n",
        "    # Rotation\n",
        "\n",
        "    ang_rot = np.random.uniform(ang_range)-ang_range/2\n",
        "    rows,cols = img.shape    \n",
        "    Rot_M = cv2.getRotationMatrix2D((cols/2,rows/2),ang_rot,1)\n",
        "    \n",
        "    \n",
        "    # Shear\n",
        "    pts1 = np.float32([[5,5],[20,5],[5,20]])\n",
        "\n",
        "    pt1 = 5+shear_range*np.random.uniform()-shear_range/2\n",
        "    pt2 = 20+shear_range*np.random.uniform()-shear_range/2\n",
        "  # Brightness\n",
        "\n",
        "\n",
        "    pts2 = np.float32([[pt1,5],[pt2,pt1],[5,pt2]])\n",
        "    \n",
        "    shear_M = cv2.getAffineTransform(pts1,pts2)\n",
        "\n",
        "    \n",
        "    img = cv2.warpAffine(img,Rot_M,(cols,rows))\n",
        "    img = cv2.warpAffine(img,shear_M,(cols,rows))\n",
        "\n",
        "    \n",
        "    return img\n",
        "#dst = transform_image(new_x_train_data[0], 360, 2)\n",
        "\n",
        "\n",
        "def dataAugment(images, labels, factor = 5):\n",
        "  new_img = []\n",
        "  new_labels = []\n",
        "  for img in range(0,len(images)):\n",
        "    for i in range(0,factor):\n",
        "      dst = transform_image(images[img], 360, 2)\n",
        "      new_img.append(dst)\n",
        "      new_labels.append(labels[img])\n",
        "      \n",
        "  return np.asarray(new_img), np.asarray(new_labels)\n",
        "\n",
        "# temp_img, temp_labels = dataAugment(new_x_train_data, train_y_wo_touching)\n",
        "# print(new_x_train_data.shape, train_y_wo_touching.shape)\n",
        "# print(temp_img.shape, temp_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n4Q3IvMUOi7_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluating models"
      ]
    },
    {
      "metadata": {
        "id": "uALOp9FkgNPA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def preprocessing_CNN(x):\n",
        " \n",
        "  ''' function for pre processing our images for CNN input\n",
        "  \n",
        "      x: already rescaled subimages \n",
        "      \n",
        "      return: x ready for input into CNN\n",
        "             \n",
        "  '''\n",
        "\n",
        "  img_rows, img_cols = 28, 28\n",
        "  \n",
        "  x_copy = np.copy(x)\n",
        "  x_copy = x_copy.reshape(x.shape[0], img_rows, img_cols, 1)\n",
        "  x_copy = x_copy.astype('float32')\n",
        "  x_copy /= 255\n",
        "\n",
        "  return x_copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oCo-NvOSbuRE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def flatten(data):\n",
        "  \n",
        "  flattened_data = []\n",
        "  for entry in data:\n",
        "    flattened_data.append(entry.flatten())\n",
        "    \n",
        "  return np.asarray(flattened_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C-EsQD86ng7B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## neural network"
      ]
    },
    {
      "metadata": {
        "id": "TNNf5G7pYH_z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "688e5d22-8bd7-4484-fdc8-2c113a299aac",
        "executionInfo": {
          "status": "error",
          "timestamp": 1521689810559,
          "user_tz": 240,
          "elapsed": 1793,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Simplistic implementation of the two-layer neural network.\n",
        "Training method is stochastic (online) gradient descent with momentum.\n",
        "As an example it computes XOR for given input.\n",
        "Some details:\n",
        "- tanh activation for hidden layer\n",
        "- sigmoid activation for output layer\n",
        "- cross-entropy loss\n",
        "Less than 100 lines of active code.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "n_hidden = 28\n",
        "n_in = 784\n",
        "n_out = 10\n",
        "n_samples = 300\n",
        "\n",
        "learning_rate = 0.01\n",
        "momentum = 0.9\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "def Sigmoid_forward(X):\n",
        "     return 1.0 / (1.0 + np.exp(-X))\n",
        "\n",
        "\n",
        "\n",
        "# class Tanh:\n",
        "#     def forward(self, X):\n",
        "#         return np.tanh(X)\n",
        "\n",
        "#     def backward(self, X, top_diff):\n",
        "#         output = self.forward(X)\n",
        "#         return (1.0 - np.square(output)) * top_diff\n",
        "\n",
        "\n",
        "def Softmax_loss(X, y):\n",
        "    num_examples = X.shape[0]\n",
        "    probs = Softmax_predict(X)\n",
        "    data_loss = 0\n",
        "    for i in range(num_examples):\n",
        "      corect_logprobs = -np.log(probs[i]*y[i])\n",
        "      data_loss += corect_logprobs\n",
        "    return 1./num_examples * data_loss\n",
        "    #loss = -np.mean ( true * np.log(Y) + (1 - true) * np.log(1 - Y) )\n",
        "    #return loss\n",
        "\n",
        "def Softmax_predict(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "    \n",
        "\n",
        "def Softmax_diff(X, y):\n",
        "    num_examples = X.shape[0]\n",
        "    probs = Softmax_predict(X)\n",
        "    probs[range(num_examples), y] -= 1\n",
        "    return probs\n",
        "      \n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0/(1.0 + np.exp(-x))\n",
        "\n",
        "def tanh_prime(x):\n",
        "    return  1 - np.tanh(x)**2\n",
        "\n",
        "def softmax_loss_naive(W, X, y, reg= 0):\n",
        "  \"\"\"\n",
        "  Softmax loss function, naive implementation (with loops)\n",
        "  Inputs:\n",
        "  - W: C x D array of weights \n",
        "  - X: D x N array of data. Data are D-dimensional columns\n",
        "  - y: 1-dimensional array of length N with labels 0...K-1, for K classes for us the one hot encoded\n",
        "  - reg: (float) regularization strength\n",
        "  Returns:\n",
        "  a tuple of:\n",
        "  - loss as single float\n",
        "  - gradient with respect to weights W, an array of same size as W\n",
        "  \"\"\"\n",
        "  # Initialize the loss and gradient to zero.\n",
        "  loss = 0.0\n",
        "  dW = np.zeros_like(W)\n",
        "\n",
        "  #############################################################################\n",
        "  # Compute the softmax loss and its gradient using explicit loops.           #\n",
        "  # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
        "  # here, it is easy to run into numeric instability. Don't forget the        #\n",
        "  # regularization!                                                           #\n",
        "  #############################################################################\n",
        "\n",
        "  # Get shapes\n",
        "  num_classes = W.shape[0]\n",
        "  num_train = X.shape[1]\n",
        "\n",
        "  for i in range(num_train):\n",
        "    # Compute vector of scores\n",
        "    f_i = W.dot(X[:, i]) # in R^{num_classes}\n",
        "\n",
        "    # Normalization trick to avoid numerical instability, per http://cs231n.github.io/linear-classify/#softmax\n",
        "    log_c = np.max(f_i)\n",
        "    f_i -= log_c\n",
        "\n",
        "    # Compute loss (and add to it, divided later)\n",
        "    # L_i = - f(x_i)_{y_i} + log \\sum_j e^{f(x_i)_j}\n",
        "    sum_i = 0.0\n",
        "    for f_i_j in f_i:\n",
        "      sum_i += np.exp(f_i_j)\n",
        "    loss += -f_i[y[i]] + np.log(sum_i)\n",
        "\n",
        "    # Compute gradient\n",
        "    # dw_j = 1/num_train * \\sum_i[x_i * (p(y_i = j)-Ind{y_i = j} )]\n",
        "    # Here we are computing the contribution to the inner sum for a given i.\n",
        "    for j in range(num_classes):\n",
        "      p = np.exp(f_i[j])/sum_i\n",
        "      dW[j, :] += (p-(j == y[i])) * X[:, i]\n",
        "\n",
        "  # Compute average\n",
        "  loss /= num_train\n",
        "  dW /= num_train\n",
        "\n",
        "  # Regularization\n",
        "  loss += 0.5 * reg * np.sum(W * W)\n",
        "  dW += reg*W\n",
        "\n",
        "  return loss, dW\n",
        "\n",
        "\n",
        "\n",
        "def train(x, true, V, W, bv, bw):\n",
        "\n",
        "    # forward\n",
        "    print (x.shape)\n",
        "    print (np.dot(x, V).shape)\n",
        "\n",
        "    A = np.dot(x, V) + bv\n",
        "    Z = np.tanh(A)\n",
        "\n",
        "    B = np.dot(Z, W) + bw\n",
        "    Y = Softmax_predict(B)\n",
        "    print (A.shape)\n",
        "    print (Y.shape)\n",
        "\n",
        "    # backward\n",
        "    Ew, dW = softmax_loss_naive(W,x, true)\n",
        "    print (Ew.shape)\n",
        "    Ev = tanh_prime(A) * np.dot(W, Ew)\n",
        "\n",
        "    #dW = Softmax_dW(x,true)\n",
        "    dV = np.outer(x, Ev)\n",
        "\n",
        "    loss = -np.mean ( true * np.log(Y) + (1 - true) * np.log(1 - Y) )\n",
        "\n",
        "    # Note that we use error for each layer as a gradient\n",
        "    # for biases\n",
        "\n",
        "    return  loss, (dV, dW, Ev, Ew)\n",
        "\n",
        "def predict(x, V, W, bv, bw):\n",
        "    A = np.dot(x, V) + bv\n",
        "    B = np.dot(np.tanh(A), W) + bw\n",
        "    return (sigmoid(B) > 0.5).astype(int)\n",
        "\n",
        "# Setup initial parameters\n",
        "# initalizing on random wieghts\n",
        "\n",
        "V = np.random.normal(scale=0.1, size=(n_in, n_hidden))\n",
        "W = np.random.normal(scale=0.1, size=(n_hidden, n_out))\n",
        "\n",
        "bv = np.zeros(n_hidden)\n",
        "bw = np.zeros(n_out)\n",
        "\n",
        "params = [V,W,bv,bw]\n",
        "\n",
        "# Generate some data\n",
        "\n",
        "X = flatten(new_x_train_data)\n",
        "\n",
        "T = keras.utils.to_categorical(train_y_wo_touching, 10)\n",
        "\n",
        "\n",
        "# Train\n",
        "for epoch in range(100):\n",
        "    err = []\n",
        "    upd = [0]*len(params)\n",
        "\n",
        "    t0 = time.clock()\n",
        "    loss, grad = train(X, T, *params)\n",
        "    params -= upd\n",
        "    upd = learning_rate * grad + upd\n",
        "    \n",
        "#     for i in range(X.shape[0]):\n",
        "# #         loss, grad = train(X[i], T[i], *params)\n",
        "\n",
        "#         for j in range(len(params)):\n",
        "#             #params[j] -= upd[j]\n",
        "\n",
        "#         for j in range(len(params)):\n",
        "#             upd[j] = learning_rate * grad[j] + momentum * upd[j]\n",
        "\n",
        "    err.append( loss )\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49828, 784)\n",
            "(49828, 28)\n",
            "(49828, 28)\n",
            "(49828, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-8e199713092a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mupd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mupd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mupd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-8e199713092a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(x, true, V, W, bv, bw)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mEw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax_loss_naive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mEv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtanh_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-8e199713092a>\u001b[0m in \u001b[0;36msoftmax_loss_naive\u001b[0;34m(W, X, y, reg)\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# Compute vector of scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mf_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# in R^{num_classes}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# Normalization trick to avoid numerical instability, per http://cs231n.github.io/linear-classify/#softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (28,10) and (49828,) not aligned: 10 (dim 1) != 49828 (dim 0)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Mf3_LxAQgRGI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31d6a770-84ca-47f6-f762-d68e1a30c8c9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521685177739,
          "user_tz": 240,
          "elapsed": 691,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "flatten(new_x_train_data).shape"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49828, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "Dl1avYc2YuiG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning attempt"
      ]
    },
    {
      "metadata": {
        "id": "TTLgoQY5xKGb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 29
            },
            {
              "item_id": 30
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1306
        },
        "outputId": "6c49bd31-d344-43a4-9cf6-e4dc8901eed8",
        "executionInfo": {
          "status": "error",
          "timestamp": 1521687500448,
          "user_tz": 240,
          "elapsed": 11120,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''Transfer learning attempt\n",
        "\n",
        "\n",
        "1 - Train a simple convnet on the MNIST dataset \n",
        "2 - Freeze convolutional layers and fine-tune dense layers\n",
        "   for the classification of digits from our dataset.\n",
        "Get to 99.8% test accuracy after 5 epochs\n",
        "for the first five digits classifier\n",
        "and 99.2% for the last five digits after transfer + fine-tuning.\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "now = datetime.datetime.now\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "# number of convolutional filters to use\n",
        "filters = 32\n",
        "# size of pooling area for max pooling\n",
        "pool_size = [3,2]\n",
        "# convolution kernel size\n",
        "kernel_size = [4,3,2]\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "\n",
        "def train_model(model, train, test, num_classes):\n",
        "  \n",
        "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
        "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
        "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    t = now()\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test))\n",
        "    print('Training time: %s' % (now() - t))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test score:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "x_train = new_x_train_data\n",
        "y_train = train_y_wo_touching\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# # create two datasets one with digits below 5 and one with 5 and above\n",
        "# x_train_lt5 = x_train[y_train < 5]\n",
        "# y_train_lt5 = y_train[y_train < 5]\n",
        "# x_test_lt5 = x_test[y_test < 5]\n",
        "# y_test_lt5 = y_test[y_test < 5]\n",
        "\n",
        "# x_train_gte5 = x_train[y_train >= 5]\n",
        "# y_train_gte5 = y_train[y_train >= 5] - 5\n",
        "# x_test_gte5 = x_test[y_test >= 5]\n",
        "# y_test_gte5 = y_test[y_test >= 5] - 5\n",
        "\n",
        "# define two groups of layers: feature (convolutions) and classification (dense)\n",
        "feature_layers = [\n",
        "    Conv2D(filters, kernel_size[0],\n",
        "           padding='valid',\n",
        "           input_shape=input_shape),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters, kernel_size[1],\n",
        "           padding='valid',\n",
        "           input_shape=input_shape),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=pool_size[0]),\n",
        "    Dropout(0.25),\n",
        "#     Conv2D(filters, kernel_size[2]),\n",
        "#     Activation('relu'),\n",
        "#     MaxPooling2D(pool_size=pool_size[1]),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "]\n",
        "\n",
        "classification_layers = [\n",
        "    Dense(128),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes),\n",
        "    Activation('softmax')\n",
        "]\n",
        "\n",
        "# create complete model\n",
        "model = Sequential(feature_layers + classification_layers)\n",
        "\n",
        "# train model for mnist\n",
        "train_model(model,\n",
        "            (mnist_x_train, mnist_y_train),\n",
        "            (mnist_x_test, mnist_y_test), num_classes)\n",
        "\n",
        "# freeze feature layers and rebuild model\n",
        "for l in feature_layers[2:]:\n",
        "    l.trainable = False\n",
        "\n",
        "# transfer: train dense layers for new classification task [5..9]\n",
        "train_model(model,\n",
        "            (x_train, y_train),\n",
        "            (x_test, y_test), num_classes)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "56576/60000 [===========================>..] - ETA: 0s - loss: 0.2884 - acc: 0.9102"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-013335f0f99c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m train_model(model,\n\u001b[1;32m    119\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mmnist_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             (mnist_x_test, mnist_y_test), num_classes)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# freeze feature layers and rebuild model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-013335f0f99c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train, test, num_classes)\u001b[0m\n\u001b[1;32m     58\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m               validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training time: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetch_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmake_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mbuild_results\u001b[0;34m(self, session, tensor_values)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m           \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m           \u001b[0mj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_handles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "k-KEwE6lYoHZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Simple CNN "
      ]
    },
    {
      "metadata": {
        "id": "lMN1bJ03nnpm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 23
            },
            {
              "item_id": 24
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1442
        },
        "outputId": "67547856-0a8f-4c1d-f3c9-a95dfa966876",
        "executionInfo": {
          "status": "error",
          "timestamp": 1521687513126,
          "user_tz": 240,
          "elapsed": 6976,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''Trains a simple convnet on the dataset.\n",
        "'''\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 16\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "x_train = new_x_train_data\n",
        "y_train = train_y_wo_touching\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print(x_train[0].reshape( img_rows, img_cols).shape)\n",
        "\n",
        "\n",
        "# example way of showing \n",
        "# plt.imshow(x_train[0].reshape(img_rows, img_cols),cmap='gray')\n",
        "# plt.show()\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (39862, 28, 28, 1)\n",
            "39862 train samples\n",
            "9966 test samples\n",
            "(28, 28)\n",
            "Train on 39862 samples, validate on 9966 samples\n",
            "Epoch 1/16\n",
            "21760/39862 [===============>..............] - ETA: 4s - loss: 0.9045 - acc: 0.7183"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-37272cb950c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Ow5Mokp6Yjvd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cross validation"
      ]
    },
    {
      "metadata": {
        "id": "-bEa_RsPXlTr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def create_model(dropout = 0.2, optimizer=Adam() ,activation_fct = 'relu'):\n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                   activation=activation_fct,\n",
        "                   input_shape=(28,28,1)))\n",
        "  model.add(Conv2D(64, (3, 3), activation=activation_fct))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation=activation_fct))\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Dense(num_classes, activation='softmax')) #last layer activation is always softmax\n",
        "\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3XBEz16RXnBp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "1ed575a7-232a-4451-b79f-63a89b313724",
        "executionInfo": {
          "status": "error",
          "timestamp": 1521687613026,
          "user_tz": 240,
          "elapsed": 91074,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "seed = 7\n",
        "\n",
        "num_classes = 10\n",
        "img_rows, img_cols = 28, 28\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "num_classes = 10\n",
        "\n",
        "x_train = new_x_train_data\n",
        "y_train = train_y_wo_touching\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, \n",
        "                                                    test_size=0.33, random_state=42)\n",
        "\n",
        "\n",
        "# format X data correctly\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# one hot encoding of y\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(y_test.shape,x_test.shape)\n",
        "\n",
        "epochs = [5,10,15]\n",
        "batch_size = [50,64,100]\n",
        "dropout =[0.2,0.3,0.5]\n",
        "activation = ['relu','sigmoid']\n",
        "optimizer = [Adadelta(),Adam()]\n",
        "\n",
        "# one example of the way we did hyperparameter tuning using (here for epochs) \n",
        "for e in epochs:\n",
        "  # create model\n",
        "  model = KerasClassifier(build_fn=create_model, epochs=e, \n",
        "                          batch_size=64, verbose=0)\n",
        "  \n",
        "  # impliment cross validation\n",
        "  cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=seed)\n",
        "  # get cross val scores\n",
        "  scores = cross_val_score(model, x_train, y_train, cv=cv)\n",
        "  # print scores\n",
        "  print(\"feature value is: {0}\".format(d))\n",
        "  print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(33384, 28, 28, 1) (33384, 10)\n",
            "(16444, 10) (16444, 28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-fcd8410db1be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# print scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature value is: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %0.2f (+/- %0.2f)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "bUYY2Svhi5uo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SVM with preprocessed data"
      ]
    },
    {
      "metadata": {
        "id": "KwreSZU2ygte",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def flatten_data(data):\n",
        "  ''' list of data to flatten \n",
        "      example of change: (40 000 entries,28,28) ----> (40 000 entries,28x28=784)\n",
        "  '''\n",
        "  new_data = []\n",
        "  for entry in data:\n",
        "    new_data.append(entry.flatten())\n",
        "    \n",
        "  return np.asarray(new_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D2druev9y-I5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "624caeaf-6587-4971-f24d-8520a9cacf7b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521405930500,
          "user_tz": 240,
          "elapsed": 374,
          "user": {
            "displayName": "Nadeem Ward",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102970361462901564389"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#flatten the new data\n",
        "\n",
        "print(new_x_train_data.shape)\n",
        "flat_new_x_train_data = flatten_data(new_x_train_data)\n",
        "print(flat_new_x_train_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49828, 28, 28)\n",
            "(49828, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KFAyJSD4jAAs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f1db35d4-5cd0-42be-d639-a412f951f9f1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521400409927,
          "user_tz": 240,
          "elapsed": 311,
          "user": {
            "displayName": "Nadeem Ward",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102970361462901564389"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# split the data\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(flat_new_x_train_data, train_y_wo_touching, test_size=0.2, random_state=42)\n",
        "print (x_train.shape, y_train.shape)\n",
        "print (x_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000,)\n",
            "(39862, 784) (39862,)\n",
            "(9966, 784) (9966,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bYmIdi3POJDa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "svm = svm.SVC(kernel='rbf') # svm with different kernel\n",
        "svm = LinearSVC() \n",
        "svm.fit(x_train, y_train)\n",
        "preds = svm.predict(x_test)\n",
        "acc = accuracy_score(y_test, preds)\n",
        "\n",
        "print('got accuracy: {}'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rvAjGtBlLR0g",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ed420f3-b4ad-4422-dcdd-045d20061179",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521507386855,
          "user_tz": 240,
          "elapsed": 1270,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create & upload a file.\n",
        "uploaded = drive.CreateFile({'title': 'ensemble.csv'})\n",
        "uploaded.SetContentFile('ensemble.csv')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1yn3i4EMoXMLVxFPNFBUrIbV5h46JoG85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v1I2xk8xiK6j",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 2
            },
            {
              "item_id": 3
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "outputId": "0c2823e9-7aac-489b-865b-4dd7a90eaa80",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521435189689,
          "user_tz": 240,
          "elapsed": 700,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# # preprocess the dataset to fit into CNN's\n",
        "# preprocessed_x_train = preprocessing_CNN(subimg_x_train)\n",
        "# print(preprocessed_x_train.shape)\n",
        "\n",
        "# # turn the y into categorical\n",
        "# preprocessed_y_train = keras.utils.to_categorical(backup_train_y, num_classes)\n",
        "\n",
        "\n",
        "#display preprocessed image [0]\n",
        "i = 10\n",
        "plt.imshow(backup_train_x[i].reshape(64,64),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(new_x_train_data[i].reshape(28,28),cmap='gray')\n",
        "plt.show()\n",
        "predictions[i].argmax()\n",
        "#display the expected output\n",
        "#print(preprocessed_y_train[0])\n",
        "\n",
        "\n",
        "# preds = model.predict(preprocessed_x_train)\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFMCAYAAABCsp4mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztnXt0VfWVx7+RiJEEREISCcj7acE3\nrSCoWMQF7RTqtIoZ69SOrZQl6swwhCLWspxxqqjjq2uwOjCzWh3iwlkuZ4oDrYr1EeKrKiAqoRII\ngRBCeEgShHDnD1ay7tm/b3J3rskl1/l+/rq/nd8553fO+Z2dc/bev70zYrFYDEIIIdrklJM9ACGE\nSAekLIUQwoGUpRBCOJCyFEIIB1KWQgjhQMpSCCEcZCa74b333osPPvgAGRkZWLRoEc4999yOHJcQ\nQnQpklKWb731FioqKlBSUoKtW7di0aJFKCkp6eixCSFElyEpZVlaWoqpU6cCAIYNG4YDBw7g888/\nR05ODu2fl5fX8vuPf/wjLrvsMpxyStQCkJGREWzH4uWPHz+ecHxsX0zmOV48r776Ki6//PKk9u3F\n7ivZfcefy7p163DFFVe4rp1nTACC+2fbXpqamgLZ0aNHW36//vrrmDRpEu1n6d69eyA7/fTTE/br\n1q1b0IfNhT179kTax44dC/oUFBS0/F69ejVmzJgR7Itdq88//zyQHTx4MNLu169f0Gfnzp2BbNiw\nYZH2rFmzgj7snDMzT6iDW265BU888QS++OKLoE/8vWnGnh/b96mnnhrITjvttEibzTN7DQCgoqIi\n0q6qqmr5vWLFCtx0003Ytm1bsF1jY2ObbQDYv39/IGsmqRm+d+9enHnmmS3tPn36oKamxrXtmDFj\nkjlklyBdxz569OiTPYSkSddrDgAjR4482UNIivz8/JM9hKQZMmRIp+07aZtlPIneyP74xz9GJr1X\nsXZF7NtFurB79+6TPYSkqa2tPdlDSJry8vKTPYSkuOuuu072EJJm3bp1nbLfpJRlfn4+9u7d29Le\ns2dP5FPbctlll7X8rqmpQV5eXlp+hu/Zs4f+1+3qn+G7d+/GWWedlZaf4bW1tcjNzU3Lz/Dy8nIM\nHz487T7D77rrLtxzzz1p+RnebHLqMp/hl156KdasWQMA2LRpE/Lz81u1VwohxFeBpN4sL7zwQnzt\na1/D7NmzkZGRgbvvvvtLDyTZt0H2tpTsvjz7Z28cnn1735ytzJsUKtkxJIu9Luwti+E5H7vv48eP\nB2Nnbyqet0gGe2utr68PZPaNqUePHkEf+9KQk5ODw4cPR2S2DfA3tuzs7EibmSN69eoVyCZPnhxp\n9+7dO+jDzEkHDhxo+V1ZWYkRI0YEfdjzZu89m2dsfhw6dCjSZve0b9++gcx+xdp7NXXqVFRXVwfb\n2bfU9prUkrZZzp8/P9lNhRAi7dAKHiGEcCBlKYQQDjokdCgRHeXhZdsyz2JHesOT3c7j7Wd4bKQM\nz/HYtfLYSJmdysqY3S9ZD3azVza+be1Z1pPa2r7Y2K19kHl92dg994J5XK0dk9knPV5mdvxLL700\nkFmveXzkSjPMFhhvIy0sLKTbMa+9tRkyey+7xllZWZG2ve8An7M9e/aMtPv06RNpHz16lEat2Oty\nzjnnBH3aQm+WQgjhQMpSCCEcSFkKIYQDKUshhHDQZRw8XueKlTFDvMe50ZEB2tbADAALFiyItK+9\n9tqgzy9+8YtA9vd///eR9vXXXx/02bRpUyCzjgx7fsePH6fGchYAnqgP4HN2MIO9Dez2LIPLzs4O\n+nmXKDLHSUNDQ8I+DOtYYAHh1sHT1NSEffv2RWQsYJo5p+KT1QDAxIkTgz7Dhw8PZPaZYONkgfHx\nQe81NTVYv359m32a8SwDZffG3kPr8AH4/LD94q/dkiVL8PTTT9N92UULLFi/uLg4kDWjN0shhHAg\nZSmEEA6kLIUQwoGUpRBCOEiJg8dDstl1mPMh2ZUqDJt5ZdmyZUGfv/zLv3Tty/LAAw8k7GMdRQDw\nwx/+MJDZ82GOG+85W9j1tDJvDkPbz7PvU089NZAxJwJbJcJk9jowRxRzuFiHAMs6xHIkepJdDx06\nNJCNGjUq0v7a176WcD8MturmpZdeCmTbt28HADz++ON47rnn6Hbsnp5xxhmRNltdxRyxNusQw5M1\nyuag3L9/P12hZPu1Nwm53iyFEMKBlKUQQjiQshRCCAcnLSjdk5HGY8/yYu1UX//614M+LKHxFVdc\nEWkna59MlhkzZgSy/v37B7LKysqE+/IE/jP7HZNZ25UnAJ3BAsKtPfLYsWOBDdZbH4YtPrA2NU8A\nMxAGcrOsPHZc+/fvD8YwduzYYDs2H22lQhtM3xpbt26NtNeuXRv0YUHp8ffwyJEjyM3NDfocOXIk\nkNlzZvfGYwNm85Mdz84rmzk9Ly+PZj6ytHdhit4shRDCgZSlEEI4kLIUQggHUpZCCOEgJQ4eayw/\n/fTTg7KUzHjNjOye7DNjxowJZI888kikff7557c+4C7OvHnzApnNVsSui6eEA3OgJevgYQHanow/\nVnbgwIFAxhYjsGBoT7lab4kKm3GHOREGDx4caffv3z+Ya9Zx09oYrHODBYm/8cYbgey9996LtNk9\nZc6beIdHz5496TPJrruda2zueTJesT4sM5AtEWznYu/evWlQ+pdFb5ZCCOFAylIIIRxIWQohhAMp\nSyGEcJASBw+rA+2pGcyMydaozgzx48aNC2Tp7NCxsFrRiYzePXv2pNfK9mOrGpijxmaMYas2GNaI\n71lpcfTo0WDs1kkDhGUfAD6v7OoVWxYB4M6UQYMGRdqXX3550MdmqfrOd74TZOVhq1KqqqoCmV0h\n9Morr7jGaR0szFHK7lf8yqnDhw9TpxMrUWHPj5VZsatsgND5xsbJVldZmZ1T3/rWt9xlatqD3iyF\nEMKBlKUQQjiQshRCCAcpsVmyLOXMFmFh9ixrb2J2uDvvvLOdI0wvVq5cGcisDc/aInNycqjt0WaP\nZvY0T4Z1Zl9mWHsasz1a+2tBQUFwPt6M5MxOZW1sLIuTzTYFhDY2ljXcztmjR4+ivLw8Itu1a1ew\n3SeffBLIKioqIm1mk7XXCgjPec2aNUEflmn+Zz/7Wcvviy66CJMnTw76/PnPfw5kNsCdLQRg9k87\nZ1gmMrZowS5osfbXPXv24MCBA8F2nn23hd4shRDCgZSlEEI4kLIUQggHUpZCCOEgI5ZsfdR2EJ9l\n5bPPPsOQIUMCQz8zxDMDrA3CZZlKbrjhhkD2k5/8JNIePXp024NOM2ypgnhHzZYtWzBixAjqvLEO\nM9aHOeOswd6bacYGibP7Hj8ly8vLMXz48MD4zxx7LPB54MCBgWzAgAGRNstsw8q02kfFZiECgI8/\n/rjl92uvvYbJkycHDh7roAC4s8he4wsvvDDoc9lllwWyadOmRdoXXXRR0CdZWPnmffv2RdrM+Wb7\nAEB1dXWkzRx0zFFjHTrxc6OyshIDBgygY7AwJ5d1eMajN0shhHAgZSmEEA5cyvLTTz/F1KlT8dvf\n/hbAiTixH/zgBygqKsLtt9/uXhcshBDpSkJlWV9fj3vuuQcTJkxokT366KMoKirCM888g0GDBmHV\nqlWdOkghhDjZJFzB0717dzz55JN48sknW2RlZWVYsmQJAGDKlClYvnw5ioqKWt2HjdQ/fvy4KxW9\nR8YM8U8//XQg+8///M9Im9Vp/qu/+qtAtn379pbf8+fPR79+/RLuG+ArQDqTf/mXf4m07T+wK6+8\nko7TOhFYxhh2H+zXBHMMsVUbdl8si4111IwcOTJw1FgnDcBXjngy/MTf42Z2794dyGwWIOaQsE6D\njz76KHB0sew6bJw2g9GLL74Y9Ek1tmQFEF4/9kyyGuvWecMcusxJaOeQ7XPw4EE696wz0VPXPp6E\nyjIzMzPwYDY0NLR4I3Nzc+mkEUKIrxLu0KHHHnsMZ555Jm644QZMmDABpaWlAE6sXy0uLqbrlZv5\n5JNPMGrUqI4ZsRBCnASSSqTRo0cPNDY2IisrC9XV1cjPz2+zf3zcV0VFBQYNGuSqDsiwr+rslZ/F\n7tlX9a/aZ/jvf//7SDv+M/yJJ57ALbfc4voMZ5+Ins9wFrPGPoXs/hN9hq9evRozZszo1M9w9mXU\nEZ/htbW1yM3NDeYeez9h4zzvvPMi7ddffz3ok2qYua0rfYYfPHgQvXr1cn2Gs8QdLHa2maSU5cSJ\nE7FmzRrMnDkTa9eupdlJ4rEXgV0UpuA8JVjZdp6MyG+99VYgKysrC2TxE3v+/PlUcaRaMTKuuuqq\nSPuhhx6KtLdv304VoYWVP/WUKGXB36zkq81Qw7LmWCZOnBgEcscHfzdTWVkZyNjkt+fIlBfbztre\nWSC5vVannHJK8FCyOfQXf/EXgeyZZ54JZKmkpKQkkL355puBzCp69g/wnnvuCWT2OixatCjowxYf\nJCI3N9eVKYv9g2qLhMpy48aNuO+++7Bz505kZmZizZo1eOCBB7Bw4UKUlJSgsLAQs2bNatdBhRAi\n3UioLMeOHYvf/OY3gXzFihWdMiAhhOiKaAWPEEI4kLIUQggHKSkrYQ3cTU1NgbGcORGYzG6XKGtN\nWzKLx1nEnFPNAfrx2HK1U6dOTXj8juTMM88M2qxs6tlnnx1p20BogDtqbOA4y0zEDOg2+wwrUxDv\nZV68eDFefvnlwINdV1cXbMc88gw7h9hyXVbuwu6fzU8b1N+nT5/A+TV+/Phgu3vvvbf1AXcCbB5/\n5zvfAXAi+H369Om4+OKLgz7XX399ILvjjjsibea0Y9fT8td//deBzGbTAsJ5xe47yzpkn+X2Onj0\nZimEEA6kLIUQwoGUpRBCOJCyFEIIBylx8FjDakZGRuD0YQZn7xJIC6thbR08niWRrB/b969+9atA\nNnLkyITj7ExsCYILL7wwWD0DAH379o20maOGrWbZvHlzpM2WB1qnDBCWEmDOFbtsccOGDa6VHN7a\n5XYpnK0jDoSOLyC8VmyZr3XwXHPNNcHKKTbPUs38+fMD2Zw5cyK/Z86cmcohUdiSRKsX7P3Mzs6m\n89g6gtpbUefk3zUhhEgDpCyFEMKBlKUQQjhIic2SZWKxMmafZMGmNlOJNxja2j6Y3YjZMKwtlY2J\nZVmZNGlSIEsl1u7Xo0cPWip227Ztkba1RQLcHmmzANmSugC3C9tMPZ5UWhkZGYHNkqXKYzZEj12R\nBVEzO6YNdK6vrw/6WFlDQ0NwjefNmxdsl2oeeeSRNv/eFeyVgD9DWTxNTU1UL9jUcZ6MV/HozVII\nIRxIWQohhAMpSyGEcCBlKYQQDlLi4LGOk1gsFgQQM6cMM9JamIOAOWE8AanMcGydNywAva0ywKni\nwQcfjLTj67XMnTsXv//972mGH1sHxbYBfm/sterZs2fQh5XVtTJWyM46p773ve8FZSxYFhvmJGRB\n7zb7EqsZs2HDhkBmg/N37doV9Nm/f3/L74cffhi//e1vA6ePKgucwDoOzzrrrKAPcxxaJyHLIsVK\nd3gWprSF3iyFEMKBlKUQQjiQshRCCAdSlkII4SAlDh5rgD1+/HjgcGEZY5jzxsJKJTDnjTUKsz5s\nDHb/qXbm3HbbbYGM1Ty3jhnrHNu2bRutq21XSLBa2MOGDQtkw4cPj7QHDx4c9LGlLYBw5RRzHtm6\n3j169AicKfGlJ9qSxTtcmrH3lK0SYWUJrAOJrQK79tprg7ZdwXPdddcF232VePLJJwMZWxH105/+\nNNL2rsZLNGfr6+tdzhs5eIQQohOQshRCCAdSlkII4SAj1t50wUkQn2F679696Nu3b5AFiAUPsyw5\n1m7E7A623CoQ2jk8pTkB4J/+6Z9aft90002ubb4MNusPy17EztlmUIm/nrt27UK/fv3oOdvSt+ed\nd17Qp6CgIJBZWxIL0N6+fXsgs4HdrE+87biiogKDBg0KjsfsjN5M6fb6eTNQ2bl31113BX1uvfVW\n1xi+Sjz++OOR9s9//vOgj7cygcVT1jp+3836hc11G6jOjr9ly5ZWx6I3SyGEcCBlKYQQDqQshRDC\ngZSlEEI4OGlZhzxGdk/QKDPqs+BWG+DODMcswH358uUtv7+Mg2fr1q2B7IYbbghkNjMQc2SwjCo2\nY8tFF10UaX/3u99FYWFhsJ3dPwvs/uCDDwKZdcywcrkssNted1bilgWuW5ktL9sabH5YGZsLr776\naiCz85FlTEoX2H22DlW2AOPTTz8NZBUVFZE2y/7E5myyDh7rHLb3MyMjw1Vau70lifVmKYQQDqQs\nhRDCgZSlEEI4kLIUQggHJ61uuMfQz7BGdpZVhmU4san99+7dG/QZMGBAILMrXO6+++6gD0t9//zz\nz0fazFnFHEp2nPGrn5q54IILApl1NtgVPYWFhbSshM2IU15eHvRh19jeL5YhismY08diDfhNTU3B\nCi9vWRDmWLCGfubM6YrOGzZfWJkTW5aDZYSaP39+IGvO3rNx40aMHTuWOu3YSjvPqjqPo43hcfyy\ntqdMjXfFV8tY2tVbCCH+nyJlKYQQDlyf4ffffz/effddHDt2DLfccgvGjRuHBQsWoKmpCXl5eVi6\ndKn7M1oIIdKRhMpy/fr12LJlC0pKSlBXV4fvfve7mDBhAoqKijB9+nQ89NBDWLVqVZsZxBPZGABu\ns/TYm5h98uDBgwllLED7qquuCmTnnHNOpF1dXR30sfZJILSP2OzfALfpXXLJJZH2xRdfHPRhJWar\nqqoibRtI/uabb2L9+vXBdiyg12JtYKwfKz/M7E22pC2zgdntTjvttGAueIKVWxuXleXn5wd9Uk1Z\nWVkgs9l8Nm7cGPSx9x0Ir7HXhlhXVxf5za6nJ0kZ27enMoE3c7ntxxa9MJulPR4Lnm+LhJ/h48eP\nxyOPPALgRA3thoYGlJWV4Zvf/CYAYMqUKSgtLW3XQYUQIt1IqCy7devW8maxatUqXHbZZWhoaGh5\nE8zNzaVLp4QQ4quEO/nvH/7wBzzxxBNYvnw5pk2b1vI2WVFRgeLiYqxcubLVbTdv3owxY8Z0zIiF\nEOIk4Ppof+2117Bs2TI89dRT6NmzJ3r06IHGxkZkZWWhuro6oc3n8ssvb/m9Z88e5OfnB3YGVlWQ\n2cpsP2bz8tgsbeIJALj66qsDWbzN8o477sCcOXOCPh1ps7TxfcnaLD/55JOW36tXr8aMGTOStlmy\ncdp+zE7FbJZ2X4lslpWVlRgwYECH2iztWFlyCFaZsjNJtc2SXavmGN+dO3eif//+NBkFu56eyqnJ\n2iyZ38L2iz+Xmpoa5OXl0XheG7PM/CTxz40lobI8dOgQ7r//fvz7v/97y02YOHEi1qxZg5kzZ2Lt\n2rWYPHlym/tgDh4rYwNnF88aZW0Qd2sy66iZNWtW0IeN4bnnnmv5fccdd+DZZ58N+vTs2TOQ2YDe\n/v37JxwTECpLZoT+8MMPA5l9kHbs2BFpv/XWW/Qfkn0gmILzRDqwwHymCO0kZmOyD9aRI0eoEd/i\nLV1grylTjDZYHwiDu5miilcAAwYMQGVlJXbv3h3pw86ZZaCyQehMAXheKDzODiCqdJgyBXzK0uuo\n8WT9YfvyBKV7HI7tzTqUUFmuXr0adXV1uOOOO1pkv/zlL7F48WKUlJSgsLCQKh4hhPgqkVBZXnfd\ndbQo/IoVKzplQEII0RXRCh4hhHAgZSmEEA5OWtYhaxRmpSCYcdc6b1gmFpaVZ+bMmZE2M3r/7ne/\nC2Tvv/9+pN2rV6+gD/O+234TJ04M+rBwqvhVFADwxhtvBH1sGn8g9LbbEgF5eXm0trd1djDng8ej\nzIzl3ntqSdYQ74yCC5wXrC46I76GPAAsXbo06BN/XbZs2YIpU6YE18qb7cbOBXYdcnNzA5m9xsyj\nzBxy8dcvFotRhxJzOLZVx7stWaL9tCZL1CcWiwVZt4DwmW/vEm29WQohhAMpSyGEcCBlKYQQDlJi\ns7S2giNHjgQrOZhNg60gsPam8847L+jD7IPW1vn2228HfTZv3hzIrE2IZY9mK5jiVy0BwNChQ4M+\nLIORTUry8ccfB32YPcYGJ9trd/ToUZctyWv38/ZLV5hdsbi4ONJm9t2cnJxIOxaLuWyuzD6Y7MIN\na2NmzxGz2cfvq6mpiZ6fJ1OPNyjdA9tXMnZM73ZtoTdLIYRwIGUphBAOpCyFEMKBlKUQQjhIiYPH\nGopPPfXUwFDMDNzMMG4DiL/xjW8EfVj52BdffDHSZqmYPFlyWKD1pZdeGshswPmhQ4eCPps2bQpk\n1snEgodtCi4gvMbWoXX06FFXuitvNp+vEt50b/b6MYcLK+PrKRXLnDB2u9NPPz3hmIDQOcWcOex5\ni3e6Hj9+nDp42PFay1AUj8dR05HzjN1T6/hiiy3aQm+WQgjhQMpSCCEcSFkKIYQDKUshhHCQEgeP\nrRnTp0+fwKDNnCsDBw4MZOPGjYu0WUkHturlvffei7SZAdhTg3z8+PFBn3PPPTeQWQcLq5/CVgxZ\nIzdzVjHHlzVWW+dD9+7dqVHfg6cOtHelRTLbxWIxl/E/2dUeXpJx8LAxsDExB4/dPyshwbBj8NRO\nB8L6SGyepXr1TEduZ+exHDxCCNEJSFkKIYQDKUshhHCQEpulzZKTnZ0dZO1mGcjHjh0byDzlSFkN\nZmt/YXY4lvHcBpczmyWzfdhStJ999lnQZ9++fYHM2o1YlheWHd5uZ8u75uTk0BLB9jp4bG4Mb3bs\nVGcrSnYMnpLA7N6w68cC1T3b2eN5M8bb+cjmeqKywa0dy5vl3ZLsHEoWtq9kM9Y3ozdLIYRwIGUp\nhBAOpCyFEMKBlKUQQjhIiYPHZs45fPhwYNAeMWJEsN3w4cMDmQ2s3rp1a9Bnw4YNgezss8+OtL2B\nwbZEBSvpsHfv3kBmg9CZU4YFGdsx2BK3ADe+2wwxLMMKyyJjj+d18NgxJGucTzbY/MvgybTEsuvY\n68fGZbfr1q1bcI29GbY8JRzY/bLHY+fH5kK8jP0d4E4RO3ZvUHpH3Ve7n4yMDFc2JgWlCyFEJyBl\nKYQQDqQshRDCgZSlEEI4SImDZ//+/UHbrjBhzhy7KgUIy0Fs2bIl6MOM0NZRwvZ98cUXBzJbE5yl\n6K+srAxk27dvj7RZSQCWMamuri7SZgZ8VtrCno9drVNfX08dBtbInWzd8GQz1HRVOqoER0ZGRnAP\nWYYtdjx7v7yOKDv/2XYsY5JdwcMcnp15TzuqZr03S5VW8AghRCcgZSmEEA6kLIUQwkFKbJY2IPvz\nzz/H6NGjIzKWEZyVj62trY20rW0QAIYOHRrIrN2UZeC55JJLApm1LzFbyEcffRTIrE2I2Rk9mVGY\n3Yjty8Iy3bBAY08mm2QDij3n19mZZpK1sXmyKHnK5Xbr1i0YgycrOuAL/PdcP6+t08LOzxOUzvCM\n3RvMnmwJXbudbJZCCNEJSFkKIYSDhJ/hDQ0NWLhwIWpra3HkyBHMnTsXo0ePxoIFC9DU1IS8vDws\nXbqUfkYIIcRXhYTK8pVXXsHYsWPx4x//GDt37sSPfvQjXHjhhSgqKsL06dPx0EMPYdWqVSgqKkrF\neIUQ4qSQUFnOmDGj5feuXbtQUFCAsrIyLFmyBAAwZcoULF++vE1lycpKDBkyJCJjb6Y7d+4MZO+8\n806kbcvsAtx5Y4OvWQA6CxK3GWL+/Oc/B33Ky8sD2bBhwxKOiRn6rbGcBc8zbLA8S6HPDPG2n80Q\nBXBngL1WXueKp+QBG2OyjigPbOzMueG5F/Y+NDU1BfvyBKC31s/CMufYa+U9XqL9AL6sVOw6sXtj\nny1vdiQLy5yVk5MT9LNO3vZ+Dbu94bNnz8bu3buxbNky3HTTTS0Hys3NRU1NTbsOKoQQ6UZGrB3/\njjdv3owFCxagpqYG69evBwBUVFSguLgYK1eubHW7jz/+OAgVEkKIdCLhm+XGjRuRm5uLfv36YcyY\nMWhqakJ2djYaGxuRlZWF6urqYP205Yorrmj5vXv3bpx11lmRz3sAOOecc4Lt2Gf4s88+G2mzzwL2\n+WA/gy+88MKgz9VXXx3I4j8V7r77bvzoRz9KOCYg+c9wliTYwj5zbCLh+M/B7du3Y+DAgXR9uv3s\nZhUnO/Iz3BO3Gk9NTQ3y8vLclQ07CjYuFgtsib/uW7ZswYgRI4J4YTYX2Gejvafea2zzILB5xj7D\nm/e/c+dO9O/fn65hZ/uyn8on8zN837596NOnj+sznCXf3r17d6vHSTgD33nnHSxfvhzAiYzg9fX1\nmDhxItasWQMAWLt2LSZPnpxoN0IIkdYkfLOcPXs27rzzThQVFaGxsRE///nPMXbsWBQXF6OkpASF\nhYWYNWtWm/uw/5H79u2L3r17R2Tsvwor12AN2uyNw/OftLCwMOjjKTXBMgyx/9KeGsWetPbJrnBh\nK0mSXXXjcTQwOsrh0tFlJZKFfcVY7OqqrKys4D6zN0tPLXHmkPDUBGd9En2RteZUY3PBvkmyshke\nhxm7z57MR/a6dO/enX6h2bG3d34mVJZZWVl48MEHA/mKFSvadSAhhEhntIJHCCEcSFkKIYSDlGQd\nst7y/Pz8IJic2e9YRiFrw2AeXpbNPC8vL9IeOHBg0IeNwdqXWGZ2T3Arsxt1ZNbpRIHILPsN247Z\nqTxe2FSXP2V05PE8GZPiozyaeeKJJyLtDRs24MCBAxEZi/zw2vkszIbosc2xuR7veY7FYnQueOyY\nXhupHZfXNp5o7sViMWrrtB7yAQMGuI7XjN4shRDCgZSlEEI4kLIUQggHUpZCCOEgJQ4eG4Deu3fv\nIHiXBepWV1cHMo9jgRl3+/XrF2n36tXLtZ0NbmWB8rasL5B8wLk1jnsM+EBoeGflGzwZfjz7ZiTr\nwPKUG+jIchFfBrtE1jpzWuOMM86ItDdt2hT0GT9+fCCzzwhzAnnuF7t+bH7G7+v48ePuMiTWocq2\nYws3rNPHW7LCno99bo8ePUrHcNVVV0XaI0aMCPq0hd4shRDCgZSlEEI4kLIUQggHUpZCCOEgJQ4e\nm13ktNNOC4y5NgcfwOuGe1YLMNnZZ58daTNnDsM6eJhjga3g8WRH8pR5SNbhwmBjt8fzjtPCVmgw\nx0Kq81ImCzsf5mBJBuvwBPjH3ca1AAAdGUlEQVTKMDuHWCpEVqXAU1aCOXji50csFnOvyrIkW9/c\ns2IJCJ1FdhVfTk4Opk6dGmxndQDTOW2RHjNXCCFOMlKWQgjhQMpSCCEcSFkKIYSDlDh4WNp3a8y1\nxYQAnmrN4+BhBu3c3NyE+2aOGusIsqsqWjseK/ZkSXZFTbJpxxIZ9Vvbd7IreDyrL07GShwP7Hw6\nysHjxToySktLgz5TpkwJZLb0CVvNkqhcQ2sOHuaEyc7OjrRZ7Xk2r9oqstcMW9lnV9/Z4oAjR47E\n0KFDg+3sddiwYUPQpy30ZimEEA6kLIUQwoGUpRBCOEiJzdLaNLKzswN7ltdmaVPDMzscy3Bi7RXe\n8gnWRsNsiJ6MO8xGxOw/duzMjuoJLmdlJZj9x2M39eC1PSbKjtSefXUmw4cPD2QvvvjiSRhJ27zy\nyiuBbPTo0ZE2s1kmizdw3JKsnZ2VjbHlIM4///ygzZ7v1157LdKWzVIIIToBKUshhHAgZSmEEA6k\nLIUQwkFKHDw2kDsrKytwZLBAVuYU8RiKmUHbOg28jhNrKPZmYvE4eDzHY+fCjOxWZrdrraxEss4U\nT3kPRmfWDWckW0u8KziZksXee+YETeTgbG2+MJl1xCa7cIM5dO1iEgAYNGhQpG0dPgMGDMCHH34Y\nbGfLeVRVVQV92kJvlkII4UDKUgghHEhZCiGEAylLIYRwcNJW8Bw4cCAis+UbgDArCRA6SpjBmaXt\nt/3YKh9m1LfGclsDGuAGdOtE8GZHsuNi+/asyLDbHTt2zLVah10Xht0Xc5h56lWn2uHjpauOKxnY\nfGH3Kz6rUlNTE50vbEWNdc6y55ZdT7t/tsLM1moHwixD1dXVQduu1gHCMjVWLyVCb5ZCCOFAylII\nIRxIWQohhIOTVgrXBqCysrfMzmHtfJ4AbbYdswUyPDY81seeX7JB217bWaL9t5b5Ol1tc2zcyQaS\n9+vXL5CtX78+qX11Baztj9kse/bsGcji7Zi9evWiQeJscYXdP7PFezJlMX+ADThnx9u2bVukXVVV\n5cqwxey2baE3SyGEcCBlKYQQDlzKsrGxEVOnTsV//dd/YdeuXfjBD36AoqIi3H777a7CXEIIke64\nlOW//uu/ttgTHn30URQVFeGZZ57BoEGDsGrVqk4doBBCdAUSei+2bt2K8vJyXHHFFQCAsrIyLFmy\nBMCJMpzLly9HUVFRm/tgpXBtWVEWlO4x4rM+TGadTMwJxDKxWBlzDNl9A6ExOdmyC97zS5QFqKtm\n0enIcXmdPn369Im033///Q4bQ1fg4MGDkTZznNjyLED0OWUOIIA7eDzlqdkXqHXCMGcOk9kxfPTR\nR0G7oaEh4XYd7uC57777sHDhwpZ2Q0NDy0Fyc3NRU1PTrgMKIUQ6khFr41/7888/j6qqKsydOxeP\nPfYY+vfvj6VLl7YUe6+oqEBxcTFWrlzZ5kFqamqQl5fXsSMXQogU0uZn+Lp167Bjxw6sW7cOu3fv\nRvfu3dGjRw80NjYiKysL1dXVyM/PT3iQFStWtPxesGAB7r///uBT4bnnngu2Y2+tnnjJXr16BbLr\nrrsu0mZrXNlneHl5ecvv//iP/8CQIUOCPuwz3JoVWNwXi3+z+/KsHwfartK4detWDBs2zB3L6sHz\n+dwRMZzV1dUoKChIens2TptQdvPmzUnvvytiX0y8n+HNpqkNGzZg3LhxdL4wc5mFzVn2nHo+w7//\n/e8HMvvcrF69uuX322+/jfHjx2Pr1q3BdvYznK0N3717dyBrpk1l+fDDD7f8bn6z/NOf/oQ1a9Zg\n5syZWLt2LSZPntzWLoQQ4itBu1fwzJs3D8XFxSgpKUFhYSFmzZqVcBv7xnbKKacEWp4ZgNl/KOuY\nYW8vLK09e/uzsP9+dpzMwO3N1OPBviGyt91k9tNR9cFboyNXAjHnVEfu37t6q6M477zzIu0PPvig\nU49nnRvMkcG+auw89nz5AOHcYs8Ie77tdixbGHM07dmzJ9L+7LPPgjb7orDXob1zyv2Uz5s3r+V3\n/Ge1EEL8f0AreIQQwoGUpRBCOEhJ1iFrC8nMzAw8bSyIlNkUPEHizPtnx8BsGixQnXmxPVh7q9f2\n6LE1erIH2eMz+29nk0zwfEfDPJ5btmzp1GNakp1DyWLnuicgHIjaKBsaGuj9Y150O0eZx5zZP+24\n2HPL5ofdv82OdOTIkYRB90D7bdd6sxRCCAdSlkII4UDKUgghHEhZCiGEg5Q4eFhZ1qqqqojMZiEC\nfMG0LACWLcG0Y2AOD7av2traSJsF5XqyFXkdPMzJZPGWnW3P39uiM50wnn2zoHR2Puy62IDlziZ+\nKWVtbS1yc3Ops6EzsXOUzWvmhInfrr6+npa0ZfPYPpPMccIWilinLjueJ4OR3a5Hjx40wN2Oq725\nePVmKYQQDqQshRDCgZSlEEI4kLIUQggHKXHw7NixI2jbfHPMKMyi/q1DgBmO+/fvH8isoZg5eNgq\nIpvfzjMmIDSEs+Mx47UnOxA7nt0/W9HTmTXCu0L9cebISDVstRqrv92Z2LnH5lSi1VWxWIw6QJgj\nlj0TFvac2n2xMbHnxsqsAy0nJ4cezzq1VDdcCCE6ASlLIYRwIGUphBAOUmKzZJmMd+7cGR2IM9u4\ntXOceeaZQZ++ffsGMk+2G2ajqaurSzgmT1ldr03P2pe82yUK2u5om2JH7W/79u2BzAZVV1dXJ50x\nvjMZPHhwIGMB0p2dpd7isVmy5y1+u1NOOYU+D4cPHw5ktp6V1xZobcwe2z/bv7WZnnrqqdT/YP0i\nLHC9LbreDBRCiC6IlKUQQjiQshRCCAdSlkII4SAlDp7XX389aFtHTa9evYLtmOPEGp2HDx8e9PGU\nvWWG6k2bNiUcQ01NTdCnsLAwkHkKunsM6CzQml0Xa+S217exsZFmdbHlBdiYmDPAHo8Z51kAs73G\n1jnA6IrOHQDYtm1bwj6pznoEAJMnT4602X1gDpD4uTZq1Cj86U9/CvqwDEr79++PtAsKCoI+FRUV\ngezgwYNttgHuSLROXTuHTj/9dFRWVgbb2fm/a9euoE9bdM1ZKIQQXQwpSyGEcCBlKYQQDqQshRDC\nQUocPGw1iS39wDKzsJUHdnXON77xjaCPLQUBhNH6NhMSAHz66aeBzJM9yJOenp0Lc9RYRwlz8DDj\nPMt2Y9vMCWOzs7AxsePZ82FZXj755JNAlpeXF8hEx7Jy5covvY+XX34Z1113XSB/5ZVXApl1uHhL\nxFinbnV1ddDHZv0CQgfSqFGjgrbNagaEz7InW1Jk+3b1FkKI/6dIWQohhAMpSyGEcJASmyXLZGyD\nr/fu3RtsN2zYsEA2bdq0SJvZ4eLLkTZjsyS/8847CfsAoa2T2SzZdjYAlgXXsmBvK2O2XCazNkN7\n/MzMTHo8ez7M/sqOZ/sx+4/sk+lNSUlJIGOLQOwzyOyMbNGJXTxiM5EBwMcffxzIzjrrrEh75MiR\nQfuDDz4ItrP7Z7bVttCbpRBCOJCyFEIIB1KWQgjhQMpSCCEcpMTBYx0gn3/+eeAQsIGlADB27NhA\nNmDAgDb33RrW4MuMycwIbVPRs+DrPXv2BDLrTGEOEE92JBYkzmSJjNX19fXo2bNnILeBuiwzEcMG\nqq9du9a1nUhvPFmHWJYo5oi1zwib1yxr09ChQyPtQYMGRdo9e/bE1KlTg+1KS0sj7Y0bNwZ92kJv\nlkII4UDKUgghHCT8DC8rK8Ptt9+OESNGADgRw3TzzTdjwYIFaGpqQl5eHpYuXequ6CaEEOmIy2b5\n9a9/HY8++mhL+2c/+xmKioowffp0PPTQQ1i1ahWKioo6bZBCCHGyScrBU1ZWhiVLlgAApkyZguXL\nl7epLK0j47TTTgtW51xwwQXBdv369Qtk1gjMav/+7//+byCzKfKZc4Wtzjlw4EAgs7CMQtbxxJwr\nnnINrBwFc+ZYR5Qd94EDB6gB3Tqs2BcCW31kj3fuuecGfboql19+eaT96quvnqSRpB/MwWnnv80M\nxvoA4byymcgAnvHKliaxjtm6ujr0798/2G7ixIltbpcIl7IsLy/HnDlzcODAAdx6661oaGhoeahy\nc3NpXRohhPgqkRFjPv04qqur8e6772L69OnYsWMHbrzxRtTX1+Ott94CcKIQUXFxcZs59D7++GOM\nHj26Y0cuhBApJOGbZUFBAWbMmAEAGDhwIPr27YsNGzagsbERWVlZqK6upq/P8Vx55ZUtv6uqqlBY\nWNhhn+Hss9HzGc4+udknxr59+1p+19fXY8iQIUEfljjAxiuyz3B2PHt+LLGF5zM8fj/79+9H7969\naYycHQOLB2UJiO1nfjp9XegzPHkuueSSQFZVVRVps2fL8xnOzD3sXc4+gxMmTGj5fe+992LRokX0\nE9uOk8VZvvzyy4GsmYTK8oUXXkBNTQ3+5m/+BjU1NaitrcU111yDNWvWYObMmVi7dm1QetPyve99\nL2jbB5fZHtkFtuUyWXaRDz/8MJCxG2FhN8baDFk2Z/bPIl7JAjxzD5tUNqCXKVQW9GttpPZ4x44d\no6VGrd2UlaZl18UTUN8VuPrqqwOZzWTD/gGyuWf/cdl/UJaamhrk5eUF94vNoa5I/EtOM3V1dYHM\nPlvsn7ItuQyELwZsOzZnbQli+yKyceNGDB48ONjOZitiJazbIqGyvPLKKzF//ny89NJLOHr0KH7x\ni19gzJgxKC4uRklJCQoLCzFr1qx2HVQIIdKNhMoyJycHy5YtC+QrVqzolAEJIURXRCt4hBDCgZSl\nEEI4SEnWIWtsHTx4cODRZR7l7du3BzKbheT9998P+rCgWGs89mYrstsxwz8LLrcOEE/gOuALSmfH\ns1EB1qmQnZ3tKlHB9s2cY9YRxMqmsrIEnck111wTyJizz8KcD17PrIdkt0uWeO8wwDNsMQdd873f\nvHkzxowZQ8fN5rGds8zxxZySVsa2Y9Eutt+WLVuCNosYsc/b2WefHfRpC71ZCiGEAylLIYRwIGUp\nhBAOpCyFEMJBShw8r7/+esvvv/u7v8Prr78elGKora0NtmMZR+zKGLZ6hi3Zs3XJWU1rlmHIGrTZ\nEky2IuOMM86ItNmSQWaEtv28Dhfbz678ycnJodt5VqUwJ5N1ELz77rtBn29/+9uBzPI///M/CfsA\nwI033hhpb968OehTWVkZyFimJc9qLg+e8gkZGRkddrxkYY49NvZ4jh07Rp05bH7YpYXsuWUr0ewK\nNvY8sFU9drtdu3ZF2gcPHsSGDRuC7ezKrdzc3KBPczY1ht4shRDCgZSlEEI4kLIUQggHKbFZvvLK\nK0Hb2nGYDYXZHm2GEW9ZWGt3Y3YVFqhr93/o0KGgD7PHWNsOOxeGtSEePnw46MPST1nbjr2eOTk5\n9FrZQF12XZi9taCgINJmNmCWXs6mrrvtttuCPvElS99++22MHz8+sDmzgH523z2ZpJhtjs1HT0ox\nC8ssxa6nd354YHZuC7vP8dfv0KFDblurvRfsnJnd1MLsoZ57ao/XrVs3et/tvtiil7bQm6UQQjiQ\nshRCCAdSlkII4UDKUgghHKTEwWON5YkCYptJlLa/tX15MsYwA7DHoO09nsVTg4T18/QBwvT71mFw\n+PBh6iyy5TzGjBkT9GHF5oYOHRppe5xcQOhYYA4zhs0+wwLlvdfKOgS8wdee+2z7sP0wZ0eyDp7m\n+ljxfPLJJ0ntK55YLOaes/aeeh1D9hlkDkj2nCbK4nT48GE6H1kGo/agN0shhHAgZSmEEA6kLIUQ\nwoGUpRBCOEiJg8cbYW9hBma7XUcZ4lvDOnTYdh7HAhsnW2lhj8dWQzBDuK3n3KdPn0j76NGjLkfN\nsGHDgj7MWG6dFCxjE7vH1sjev3//hGMaOnQo3nvvvYiMXTtW85zdG3tNPdmYGGx+WllTU1NwHexq\nJIBn1/GQ7PxnxG/XWrYkdk/tfPQ8t0zmfbYSnV9GRobLOdxe9GYphBAOpCyFEMKBlKUQQjhIic2S\nkWygurVXJJsJ21ue1I6L2cqYjcbCMs2wfSWbMcaOwWaQz8/Px8SJE4PtrD2S3QeW4cfahDz2V7ad\nx6bYrVu3IOieZV5iQccsk5TFU94VCOcMu6fsutg5etFFFwXbvfnmm4Hsb//2byNtlo3eM4+TsQVm\nZGQk/Ywkux2zzzNZogUmmZmZLls/0x1toTdLIYRwIGUphBAOpCyFEMKBlKUQQjg4aVmHrIwZ1JnM\nGm69wafWiM+M+sxgb43ALGMMMxRbZ4PHCQSE58zOj43TOnRs9qAxY8ZQo7cdF0vjz8ZuA8CZc8VT\nxqK+vj7oY7MjHT58OAgSZ04Ez3xhMOeUx7HAjmfvV48ePYKxs+syadKkhMfznAvbzkv8dq3NV0+2\nLs+1Y9t5SguzsbGFAMyB5XEotYXeLIUQwoGUpRBCOJCyFEIIB1KWQgjhICUOHmtAz8zMpLJE2zGZ\nd3WCJ1sRM7xbZ4rX4WIdHswB4lk5wrLfsFUpNqPQ4MGD22y3djwGGwNzwniw58wyGtlSE4cOHQru\nHzseM9iz8/OsWmJzwbOay47htNNOczklmczjlPSQjMMnFou5Szp0VGauZFfjsXrubM7a47W3zITe\nLIUQwoHrzfKFF17AU089hczMTNx2220YNWoUFixYgKamJuTl5WHp0qVfuhiQEEJ0ZRK+WdbV1eFX\nv/oVnnnmGSxbtgwvvfQSHn30URQVFeGZZ57BoEGDsGrVqlSMVQghThoJ3yxLS0sxYcIE5OTkICcn\nB/fccw+uvPJKLFmyBAAwZcoULF++HEVFRa3uwwYwn3766YGdg9krWAC4DZpmNg2PrZPZsjz76tGj\nR9DHkxnak20c8GWdtlnQgTAIndlM2Tlb+yALEmfX05aiZV8WnoBidg327dsXtK3dj23H8AQ6ezOL\n2+vgsZGeeuqpruBrJvMsGOjIrEPt+XtbY0i2FC47F3aNbVZ5+0wWFBTQa2UzV3my4ceTUFlWVlai\nsbERc+bMwcGDBzFv3jw0NDS0PBy5ubmoqalp10GFECLdyIgl+Nf061//Gu+99x4ef/xxVFVV4cYb\nb0RjYyPWr18PAKioqEBxcTFWrlzZ6j4+/fRTjBw5smNHLoQQKSThm2Vubi4uuOACZGZmYuDAgcjO\nzka3bt3Q2NiIrKwsVFdXB+uSLd/61rdafm/ZsgUjRoxwfYYzmeeVP9mkuonCgrZt24bCwsKgj+cz\nnH0Cs09JO072OXHWWWcFsunTp0fa8Z/qixcvxj/+4z+mzWf4f//3f7f8fv/993H++edjx44dCffN\nYJ+39jOuIz/D4/ts3LgRY8eODeYVm9ee0CHvun1Lez/Dq6urUVBQ4A4dsngTedvrwPbN5l5bn+Eb\nNmzAuHHjkv4Mt4X/4kl4VpMmTcL69etx/Phx1NXVob6+HhMnTsSaNWsAAGvXrsXkyZMT7UYIIdKa\nhK9bBQUFuPrqq3HttdcCOPGWMm7cOBQXF6OkpASFhYWYNWtWm/uwzo2srCxXkDgrn2D/G7CAcOZM\nsW9CnmBsgAcZe7BvaGw7dn72OrD/tszBU1BQEGnboO0vvviCBnLbN8K8vLygj6fUBCuFy875jDPO\niLSrqqqCPnv27Ana9n55stgAfH7Y687e9Ox8AcK3OPZmyQKk7djZ8dqbAae143n7JHr7O+WUU9xv\nlsk6eDyOL+ZQtfPftgsLC12LJFi5lLZwxVnOnj0bs2fPjshWrFjRrgMJIUQ6oxU8QgjhQMpSCCEc\nSFkKIYSDlGQdsm78xsbGwAHCnB2eiP6+ffsGfVj4iw2R8WSjAXjGJA92/9Zp0doYevfuHWnv3bs3\n6OMppWFDco4cOUIdLvZ82DWvra0NZDZ8g4WPVVdXBzK7mquysjLoM2jQoKBtHUEs5CjZUiHMIcHm\no3U2eOqiNzQ0BMfzhrbZ+cHOJdkSEoz4fbVWN5xdYzt21ofNPfucMicXm1f2Plin7xdffEGvp71+\n7XXw6M1SCCEcSFkKIYQDKUshhHCQEpslsyl4Anw9AbBseRKz6XkynHhsSd5x2vOztjqABydb2yo7\nF0/uUBYc7VlSx+y21o4KhHZotnQsNzc34fG2bNkS9LHX+NChQ8G4WLAys+kxPMvs2DW294bZLG3Q\nPRDadz12VCC8DmwOMex9ZvZdNob482lqaqLnx54RT0Z3z5Jg79Jla8tluoTZy+118S5MaUZvlkII\n4UDKUgghHEhZCiGEAylLIYRwkDD5rxBCCL1ZCiGECylLIYRwIGUphBAOpCyFEMKBlKUQQjiQshRC\nCAcpWRsOAPfeey8++OADZGRkYNGiRTj33HNTdeik+fTTTzF37lz88Ic/xA033IBdu3ZhwYIFaGpq\nQl5eHpYuXepap51q7r//frz77rs4duwYbrnlFowbNy4txt3Q0ICFCxeitrYWR44cwdy5czF69Oi0\nGDtwYr38t7/9bcydOxcTJkxIi3GXlZXh9ttvx4gRIwAAI0eOxM0335wWYweAF154AU899RQyMzNx\n2223YdSoUZ039lgKKCsri/3kJz+JxWKxWHl5eezaa69NxWG/FIcPH47dcMMNscWLF8d+85vfxGKx\nWGzhwoWx1atXx2KxWOzBBx+MPf300ydziJTS0tLYzTffHIvFYrF9+/bFLr/88rQYdywWi/3ud7+L\n/frXv47FYrFYZWVlbNq0aWkz9lgsFnvooYdi11xzTey5555Lm3GvX78+Nm/evIgsXca+b9++2LRp\n02KHDh2KVVdXxxYvXtypY0/JZ3hpaSmmTp0KABg2bBgOHDjQ7izFqaZ79+548sknI5may8rK8M1v\nfhMAMGXKFJSWlp6s4bXK+PHj8cgjjwAAevXqhYaGhrQYNwDMmDEDP/7xjwEAu3btQkFBQdqMfevW\nrSgvL8cVV1wBID3mSmuky9hLS0sxYcIE5OTkID8/H/fcc0+njj0lynLv3r0488wzW9p9+vRBTU1N\nKg6dNJmZmUFasIaGhpZX+tzc3C55Dt26dWtJX7Zq1SpcdtllaTHueGbPno358+dj0aJFaTP2++67\nDwsXLmxpp8u4AaC8vBxz5szB9ddfjzfeeCNtxl5ZWYnGxkbMmTMHRUVFKC0t7dSxp8xmGU/sK7DC\nsqufwx/+8AesWrUKy5cvx7Rp01rkXX3cALBy5Ups3rwZ//AP/xAZb1cd+/PPP4/zzz8fZ599Nv17\nVx03AAwePBi33norpk+fjh07duDGG2+M5NbsymMHgP379+Pxxx9HVVUVbrzxxk6dLylRlvn5+ZHC\nW3v27EFeXl4qDt2h9OjRA42NjcjKykJ1dTUtptQVeO2117Bs2TI89dRT6NmzZ9qMe+PGjcjNzUW/\nfv0wZswYNDU1ITs7u8uPfd26ddixYwfWrVuH3bt3o3v37mlzzQsKCjBjxgwAwMCBA9G3b19s2LAh\nLcaem5uLCy64AJmZmRg4cCCys7PRrVu3Tht7Sj7DL730UqxZswYAsGnTJuTn5wfZo9OBiRMntpzH\n2rVrMXny5JM8opBDhw7h/vvvxxNPPNGS4Twdxg0A77zzDpYvXw7ghOmmvr4+Lcb+8MMP47nnnsOz\nzz6L73//+5g7d25ajBs44U3+t3/7NwBATU0Namtrcc0116TF2CdNmoT169fj+PHjqKur6/T5krKs\nQw888ADeeecdZGRk4O6778bo0aNTcdik2bhxI+677z7s3LkTmZmZKCgowAMPPICFCxfiyJEjKCws\nxD//8z+3OzV9Z1NSUoLHHnsMQ4YMaZH98pe/xOLFi7v0uIEToTd33nkndu3ahcbGRtx6660YO3Ys\niouLu/zYm3nsscfQv39/TJo0KS3G/fnnn2P+/Pk4ePAgjh49iltvvRVjxoxJi7EDJ0w2q1atAgD8\n9Kc/xbhx4zpt7ErRJoQQDrSCRwghHEhZCiGEAylLIYRwIGUphBAOpCyFEMKBlKUQQjiQshRCCAdS\nlkII4eD/ABlmupF8rq18AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbfd6c5cb00>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbfd6c0dac8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "4uWWJl8Ei0mA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c0cb129e-90e6-44f6-f37b-aac7be285f6c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521417444311,
          "user_tz": 240,
          "elapsed": 6321,
          "user": {
            "displayName": "Nadeem Ward",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102970361462901564389"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(preprocessed_x_train,preprocessed_y_train, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.581616075744629\n",
            "Test accuracy: 0.68166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lyTshX54JUdS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "2f5f3929-67b4-40c2-aa0e-562f55967505",
        "executionInfo": {
          "status": "error",
          "timestamp": 1521507159385,
          "user_tz": 240,
          "elapsed": 346,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.download(‘ensemble.csv’)\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-84-823d44ad23ac>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    files.download(‘ensemble.csv’)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "junj_3naCSB3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline SVM ( takes a long time to train ~ 20 mins)"
      ]
    },
    {
      "metadata": {
        "id": "ajLRS7Frxbs5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def flatten_data(data):\n",
        "  print(data.shape[0])\n",
        "  new_data = np.zeros((data.shape[0],4096))\n",
        "  counter = 0\n",
        "  for img in data:\n",
        "    new_data[counter] = img.flatten()\n",
        "    counter+=1\n",
        "  return new_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RYm1mA0GvQmP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "06ec99d3-3863-4c32-927f-71d9090f0da7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521257243019,
          "user_tz": 240,
          "elapsed": 2521,
          "user": {
            "displayName": "Nadeem Ward",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102970361462901564389"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(flatten_data(train_x), train_y, test_size=0.2, random_state=42)\n",
        "\n",
        "print (x_train.shape, y_train.shape)\n",
        "print (x_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "(40000, 4096) (40000, 1)\n",
            "(10000, 4096) (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V5hLtehpHIlm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9b8c51d-106b-44f6-fe32-f2809bd85580"
      },
      "cell_type": "code",
      "source": [
        "# train SVM\n",
        "\n",
        "models = [LinearSVC()]\n",
        "names = ['SVM']\n",
        "\n",
        "for name, model in zip(names, models):\n",
        "\tmodel.fit(x_train, y_train.ravel())\n",
        "\tpreds = model.predict(x_test)\n",
        "\tacc = accuracy_score(y_test, preds)\n",
        "\tprint('Model {} got accuracy: {}'.format(name, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ModelSVMgotaccuracy0.4436082681115794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T9SFLfXq_2d1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NXEU3WZf3fwo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submitting our predictions"
      ]
    },
    {
      "metadata": {
        "id": "kgNAMDEn3exO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#pre-process for predicting\n",
        "def kagglePredict(model_name, df):\n",
        "  predictions = model.predict(cnn_x_test).argmax(axis=1)\n",
        "  df[model_name] = predictions\n",
        "  return df\n",
        "\n",
        "\n",
        "#kaggle = pd.DataFrame()\n",
        "#kaggle.reset_index()\n",
        "#kaggle[\"Id\"] = kaggle.index\n",
        "\n",
        "processed_x_test = new_data(np.copy(backup_test_x), find_largest_count_ratio)\n",
        "cnn_x_test = preprocessing_CNN(processed_x_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uit0kdNRCCjB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1986
        },
        "outputId": "55a0a917-52e3-43d1-ceb0-ca0b4e0e8ca4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521506829792,
          "user_tz": 240,
          "elapsed": 1863,
          "user": {
            "displayName": "Daoud Piracha",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108185722932791441609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#predicting\n",
        "kaggle = kagglePredict(\"Max Pixel Vanilla, CNN Batch = \" + str(batch_size)+\", epochs = \" + str(epochs), kaggle)\n",
        "\n",
        "kaggle"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Max Axes Vanilla, CNN Batch = 64, epochs = 16</th>\n",
              "      <th>Max Axes Vanilla, CNN Batch = 128, epochs = 16</th>\n",
              "      <th>Max Pixel Vanilla, CNN Batch = 128, epochs = 16</th>\n",
              "      <th>Max Pixel Vanilla, CNN Batch = 64, epochs = 16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9970</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9971</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9972</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9973</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9974</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9975</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9976</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9977</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9978</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9979</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9980</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9981</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9982</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9983</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9984</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9985</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9986</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9987</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9988</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9989</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9990</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9992</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Max Axes Vanilla, CNN Batch = 64, epochs = 16  \\\n",
              "0                                                 7   \n",
              "1                                                 2   \n",
              "2                                                 0   \n",
              "3                                                 7   \n",
              "4                                                 6   \n",
              "5                                                 1   \n",
              "6                                                 5   \n",
              "7                                                 3   \n",
              "8                                                 8   \n",
              "9                                                 1   \n",
              "10                                                5   \n",
              "11                                                2   \n",
              "12                                                9   \n",
              "13                                                1   \n",
              "14                                                0   \n",
              "15                                                2   \n",
              "16                                                3   \n",
              "17                                                0   \n",
              "18                                                0   \n",
              "19                                                3   \n",
              "20                                                3   \n",
              "21                                                0   \n",
              "22                                                6   \n",
              "23                                                1   \n",
              "24                                                6   \n",
              "25                                                0   \n",
              "26                                                2   \n",
              "27                                                8   \n",
              "28                                                3   \n",
              "29                                                0   \n",
              "...                                             ...   \n",
              "9970                                              5   \n",
              "9971                                              4   \n",
              "9972                                              9   \n",
              "9973                                              4   \n",
              "9974                                              0   \n",
              "9975                                              4   \n",
              "9976                                              8   \n",
              "9977                                              1   \n",
              "9978                                              3   \n",
              "9979                                              9   \n",
              "9980                                              7   \n",
              "9981                                              0   \n",
              "9982                                              6   \n",
              "9983                                              7   \n",
              "9984                                              8   \n",
              "9985                                              7   \n",
              "9986                                              3   \n",
              "9987                                              3   \n",
              "9988                                              6   \n",
              "9989                                              7   \n",
              "9990                                              2   \n",
              "9991                                              2   \n",
              "9992                                              3   \n",
              "9993                                              9   \n",
              "9994                                              2   \n",
              "9995                                              9   \n",
              "9996                                              9   \n",
              "9997                                              1   \n",
              "9998                                              3   \n",
              "9999                                              8   \n",
              "\n",
              "      Max Axes Vanilla, CNN Batch = 128, epochs = 16  \\\n",
              "0                                                  7   \n",
              "1                                                  2   \n",
              "2                                                  0   \n",
              "3                                                  7   \n",
              "4                                                  6   \n",
              "5                                                  1   \n",
              "6                                                  5   \n",
              "7                                                  3   \n",
              "8                                                  8   \n",
              "9                                                  1   \n",
              "10                                                 5   \n",
              "11                                                 2   \n",
              "12                                                 9   \n",
              "13                                                 1   \n",
              "14                                                 0   \n",
              "15                                                 2   \n",
              "16                                                 3   \n",
              "17                                                 0   \n",
              "18                                                 0   \n",
              "19                                                 3   \n",
              "20                                                 3   \n",
              "21                                                 0   \n",
              "22                                                 6   \n",
              "23                                                 1   \n",
              "24                                                 4   \n",
              "25                                                 0   \n",
              "26                                                 2   \n",
              "27                                                 8   \n",
              "28                                                 3   \n",
              "29                                                 0   \n",
              "...                                              ...   \n",
              "9970                                               5   \n",
              "9971                                               4   \n",
              "9972                                               9   \n",
              "9973                                               4   \n",
              "9974                                               0   \n",
              "9975                                               4   \n",
              "9976                                               8   \n",
              "9977                                               1   \n",
              "9978                                               3   \n",
              "9979                                               9   \n",
              "9980                                               7   \n",
              "9981                                               0   \n",
              "9982                                               6   \n",
              "9983                                               7   \n",
              "9984                                               8   \n",
              "9985                                               7   \n",
              "9986                                               3   \n",
              "9987                                               3   \n",
              "9988                                               6   \n",
              "9989                                               7   \n",
              "9990                                               2   \n",
              "9991                                               2   \n",
              "9992                                               3   \n",
              "9993                                               9   \n",
              "9994                                               2   \n",
              "9995                                               9   \n",
              "9996                                               9   \n",
              "9997                                               1   \n",
              "9998                                               3   \n",
              "9999                                               3   \n",
              "\n",
              "      Max Pixel Vanilla, CNN Batch = 128, epochs = 16  \\\n",
              "0                                                   7   \n",
              "1                                                   2   \n",
              "2                                                   0   \n",
              "3                                                   7   \n",
              "4                                                   6   \n",
              "5                                                   1   \n",
              "6                                                   5   \n",
              "7                                                   3   \n",
              "8                                                   8   \n",
              "9                                                   1   \n",
              "10                                                  5   \n",
              "11                                                  2   \n",
              "12                                                  9   \n",
              "13                                                  1   \n",
              "14                                                  0   \n",
              "15                                                  2   \n",
              "16                                                  3   \n",
              "17                                                  0   \n",
              "18                                                  0   \n",
              "19                                                  3   \n",
              "20                                                  3   \n",
              "21                                                  0   \n",
              "22                                                  6   \n",
              "23                                                  1   \n",
              "24                                                  4   \n",
              "25                                                  0   \n",
              "26                                                  2   \n",
              "27                                                  8   \n",
              "28                                                  3   \n",
              "29                                                  0   \n",
              "...                                               ...   \n",
              "9970                                                5   \n",
              "9971                                                4   \n",
              "9972                                                9   \n",
              "9973                                                4   \n",
              "9974                                                0   \n",
              "9975                                                4   \n",
              "9976                                                8   \n",
              "9977                                                1   \n",
              "9978                                                3   \n",
              "9979                                                9   \n",
              "9980                                                7   \n",
              "9981                                                0   \n",
              "9982                                                6   \n",
              "9983                                                7   \n",
              "9984                                                8   \n",
              "9985                                                7   \n",
              "9986                                                3   \n",
              "9987                                                3   \n",
              "9988                                                6   \n",
              "9989                                                7   \n",
              "9990                                                2   \n",
              "9991                                                2   \n",
              "9992                                                3   \n",
              "9993                                                9   \n",
              "9994                                                2   \n",
              "9995                                                9   \n",
              "9996                                                9   \n",
              "9997                                                1   \n",
              "9998                                                3   \n",
              "9999                                                8   \n",
              "\n",
              "      Max Pixel Vanilla, CNN Batch = 64, epochs = 16  \n",
              "0                                                  7  \n",
              "1                                                  2  \n",
              "2                                                  0  \n",
              "3                                                  7  \n",
              "4                                                  6  \n",
              "5                                                  1  \n",
              "6                                                  5  \n",
              "7                                                  3  \n",
              "8                                                  8  \n",
              "9                                                  1  \n",
              "10                                                 5  \n",
              "11                                                 2  \n",
              "12                                                 9  \n",
              "13                                                 1  \n",
              "14                                                 0  \n",
              "15                                                 2  \n",
              "16                                                 3  \n",
              "17                                                 0  \n",
              "18                                                 0  \n",
              "19                                                 3  \n",
              "20                                                 3  \n",
              "21                                                 0  \n",
              "22                                                 6  \n",
              "23                                                 1  \n",
              "24                                                 1  \n",
              "25                                                 0  \n",
              "26                                                 2  \n",
              "27                                                 8  \n",
              "28                                                 3  \n",
              "29                                                 0  \n",
              "...                                              ...  \n",
              "9970                                               5  \n",
              "9971                                               4  \n",
              "9972                                               9  \n",
              "9973                                               4  \n",
              "9974                                               0  \n",
              "9975                                               4  \n",
              "9976                                               8  \n",
              "9977                                               1  \n",
              "9978                                               3  \n",
              "9979                                               9  \n",
              "9980                                               7  \n",
              "9981                                               0  \n",
              "9982                                               6  \n",
              "9983                                               7  \n",
              "9984                                               8  \n",
              "9985                                               7  \n",
              "9986                                               3  \n",
              "9987                                               3  \n",
              "9988                                               6  \n",
              "9989                                               7  \n",
              "9990                                               2  \n",
              "9991                                               2  \n",
              "9992                                               3  \n",
              "9993                                               9  \n",
              "9994                                               2  \n",
              "9995                                               9  \n",
              "9996                                               9  \n",
              "9997                                               1  \n",
              "9998                                               3  \n",
              "9999                                               3  \n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "UEkFBbiR3BxY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sub = kaggle.mode(axis = 1)[0].astype(int)\n",
        "sub.to_csv(\"ensemble.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1M8RRe0Vlo8C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Downloading our predictions"
      ]
    },
    {
      "metadata": {
        "id": "4AHIcceDJVMf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YiTMkldPIZ7X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Analyzing MNIST"
      ]
    },
    {
      "metadata": {
        "id": "UqYIxYr8InrN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "def load_flattened_mnist():\n",
        "  '''returns flattened x_train, x_test and y_train, y_test of mnist dataset\n",
        " '''\n",
        "  (mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()\n",
        "  num_pixels = mnist_x_train.shape[1] * mnist_x_train.shape[2]\n",
        "  mnist_x_train = mnist_x_train.reshape(mnist_x_train.shape[0], num_pixels).astype('float32')\n",
        "  mnist_x_test = mnist_x_test.reshape(mnist_x_test.shape[0], num_pixels).astype('float32')\n",
        " \n",
        "  return mnist_x_train, mnist_x_test, mnist_y_train, mnist_y_test\n",
        " \n",
        "def pixel_norm(x=mnist_x_train, y=mnist_y_train):\n",
        "  '''function that returns the avg non zero pixel counts for each digit(label) in the image dataset\n",
        "    set to mnist images by default\n",
        " \n",
        "   input: flattened image dataset as x, labels as y\n",
        "   returns: array of average pixel counts\n",
        " \n",
        " '''\n",
        " \n",
        "  data = np.c_[x, y]\n",
        "  pixels = [0] * 10 # empty list of size 10 where we will store sum of all the digit pixel counts\n",
        "  counter = [0] * 10 # empty list of size 10 to store each time a digit is hit\n",
        " \n",
        "  for entry in data:\n",
        " \n",
        "    pixels[int(entry[-1])] += count_pixels(entry[:-1].reshape(28,28))\n",
        "    counter[int(entry[-1])] += 1\n",
        " \n",
        "  avg_pixel_mnist = [x/y for x, y in zip(pixels, counter)]\n",
        " \n",
        "  return avg_pixel_mnist\n",
        " \n",
        "mnist_x_train, mnist_x_test, mnist_y_train, mnist_y_test = load_flattened_mnist()\n",
        "mnist_norm = pixel_norm(mnist_x_train, mnist_y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}